---
title: "Strakulâ€™s Thoughts Data Analysis"
author: "David Rodriguez"
date: "September 21, 2015"
output: 
  html_document: 
    keep_md: yes
---

This document contains example code and analysis for my blog, [Strakul's Thoughts](http://www.strakul.blogspot.com). You can find the full code at my [Github page](https://github.com/dr-rodriguez/BloggerAPI_R), and a text-heavy description of the results in my [August 30, 2015 blog post](http://strakul.blogspot.cl/2015/08/data-science-my-blog-with-r.html). 
This document is recent as of September 21, 2015 and so includes a little more updated information.

# Processing

First, I'll load the data set and all relevant packages.

```{r load, message=FALSE}
alldata <- readRDS(file='blogdata.Rda')

# Convert to data frame tbl
library(dplyr)
newdata <- tbl_df(alldata) 
rm('alldata')

library(stringi)
library(ggplot2)
library(scales) # for date_time scales
```

Then, I perform some basic processing to add extra information and count the number of words, images, characters.

```{r process}
newdata <-
    newdata %>%
    mutate(title = as.character(title), 
           slabels = sapply(labels, toString), # collapse the labels list to a string
           monyear = factor(format(published,'%Y-%b')),
           published = as.POSIXct(published), #POSIXlt does not work with dplyr
           numimgs = stri_count_fixed(as.character(content),'<img')) #by tag '<img'

# Parse the content to remove HTML coding and some extra characters
my_replace <- function(x) {
    x <- gsub('<(.*?)>', '', x) # removing HTML code encapsulated within <>
    x <- gsub('\n',' ',x) # removing newline characters
    x <- gsub('&nbsp;',' ',x) # removing some extra HTML code
    x <- gsub('\"','',x) # removing explicit quotation marks
    x
}
newdata <- 
    newdata %>%
    mutate(content=sapply(content,my_replace), #this can take some time
           numchar = nchar(content), #number of characters in post
           numwords = stri_count(as.character(content),regex='\\S+')) #number of words

# Add boolean columns for posts denoting them as Astronomy, Book, or Life in Chile related posts
newdata <- 
    newdata %>%
    mutate(books=sapply(labels, function(x) {any(x %in% 'Books')}),
           astronomy=sapply(labels, function(x) {any(x %in% 'Astronomy')}),
           chile=sapply(labels, function(x) {any(x %in% 'Life in Chile')}))
```

# Results

Here are the longests posts by number of words.

```{r}
 newdata %>%
    arrange(desc(numwords)) %>%
    select(title, numwords) %>%
        print(n=5)
```

And here are the shortests posts by number of words.

```{r}
newdata %>%
    arrange(numwords) %>%
    select(title, numwords, numimgs) %>%
        print(n=5)
```

Here are top 5 posts with largest number of images.

```{r}
newdata %>%
    arrange(desc(numimgs)) %>%
    select(title, numimgs, numwords) %>%
        print(n=5)
```

Now, I'll examine the frequency of posts by month and year. I also list the average number of words and images for each month. This is better seen in the graphs below.

```{r}
newdata %>%
    group_by(monyear) %>%
    summarize(counts=n(), mean_words=mean(numwords), mean_images=mean(numimgs)) %>%
    ungroup %>%
    arrange(desc(counts)) %>%
        print
```

Now for some results regarding the type of posts I do. Here are the counts for the various combinations possible of posts related to books, astronomy, and life in Chile.

```{r}
newdata %>%
    group_by(books, astronomy, chile) %>%
    summarize(count=n()) %>%
    ungroup %>%
    arrange(desc(count)) %>%
        print
```

Here are the top 5 longests posts that are not related to astronomy, book, or Chile.

```{r}
newdata %>%
    filter(!books,!astronomy,!chile) %>%
    select(title, slabels, numwords, numimgs) %>%
    arrange(desc(numwords)) %>%
    print(n=5)
```

Given that I write so many book-related posts, lets examine how many are classified under science fiction, fantasy, or are book club books.

```{r}
newdata %>%
    filter(books) %>%
    mutate(scifi=sapply(labels, function(x) {any(x %in% 'Science Fiction')}),
           fantasy=sapply(labels, function(x) {any(x %in% 'Fantasy')}),
           bookclub=sapply(labels, function(x) {any(x %in% 'Book Club')})) %>%
    group_by(scifi, fantasy, bookclub) %>%
    summarize(count=n()) %>%
    ungroup %>%
    arrange(desc(count)) %>%
        print
```

For a more compact look, we can use the following code. 

```{r}
newdata %>%
    filter(books) %>%
    mutate(scifi=sapply(labels, function(x) {any(x %in% 'Science Fiction')}),
           fantasy=sapply(labels, function(x) {any(x %in% 'Fantasy')}),
           bookclub=sapply(labels, function(x) {any(x %in% 'Book Club')})) %>%
    group_by(scifi, fantasy, bookclub) %>%
    summarize(count=n()) %>%
    ungroup %>%
    mutate(allscifi=sum(scifi*count),
           allfantasy=sum(fantasy*count),
           allbookclub=sum(bookclub*count)) %>%
    select(allscifi:allbookclub) %>%
    unique %>%
        print
```

# Graphs

Now, we are ready to generate some graphs from our data.

First up is a histogram of when I published the data.
```{r postfreq, fig.width=9}
# Setting the binwidth to be 30 days in seconds
bin <- 30*24*3600 

ggplot(newdata, aes(published, ..count..)) + 
    geom_histogram(fill='blue', col='white', binwidth=bin) +
    labs(x=NULL, y='Number of Posts') + 
    theme_bw() + 
    scale_x_datetime(breaks = "30 days",
                     labels = date_format("%Y-%b"),
                     limits = c(as.POSIXct("2012-03-01"),
                                as.POSIXct(Sys.Date())) ) +
    theme(axis.text.x = element_text(angle=90))
```

Here's a histogram of at what time I publish my posts.
```{r posttimes, fig.width=9}
newdata <-
    newdata %>%
    mutate(times=strftime(published, '%T %z')) %>% # first as a character
    mutate(times=as.POSIXct(times, format='%T %z')) # now as a POSIXct date object

bin <- 3600 # seconds in an hour

ggplot(newdata, aes(times, ..count..)) + 
    geom_histogram(fill='darkred', col='white', binwidth=bin) +
    labs(x='Time of Day (CLT)', y='Number of Posts') + 
    theme_bw() + 
    scale_x_datetime(breaks = date_breaks("1 hour"),
                     labels = date_format("%H:%M"),
                     limits = c(as.POSIXct("00:00:00 -0300", format='%T %z'),
                                as.POSIXct("23:59:59 -0300", format='%T %z') )) +
    theme(axis.text.x = element_text(angle=90))
```

In the plot below, I examine the number of words in each post as a function of time

```{r wordvstime, fig.width=9}
lvls <- c(0,1,3,6,17)
cutlvls <- cut(newdata$numimgs, lvls, include.lowest = T)
ggplot(newdata, aes(published, numwords, col=cutlvls)) +
    geom_point(size=4) +
    coord_cartesian() + 
    labs(x='Date Published', y='Number of Words') + 
    scale_color_discrete(name='Number of Images', labels=c('0-1','2-3','4-6','7-17'))
```

The plot below shows what days I tend to publish my posts.

```{r postdays, fig.width=9}
newdata <-
    newdata %>%
    mutate(weekday=factor(weekdays(published))) # get the weekdays of my posts

summary1 <-
    newdata %>%
    group_by(weekday) %>%
    summarize(count=n())

# Manually setting the proper order and resetting the factors
lvls <- c('Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday')
summary1 <-
    summary1 %>%
    mutate(weekday=as.character(weekday)) %>%
    mutate(weekday=factor(weekday, lvls))

ggplot(summary1, aes(weekday, count)) + 
    geom_bar(fill='darkgreen', col='white', stat="identity") +
    labs(x='Day of the Week', y='Number of Posts') + 
    theme_bw()
```

# Word Cloud

The last thing I want to do is create a word cloud of the top 200 words I've used in my posts.

First, I need to load up some more packages and process the data

```{r wordcloud_load, message=FALSE}
library(tm)
library(wordcloud)
library(RColorBrewer)

# Load up the data
textdata <- Corpus(VectorSource(newdata$content))

# Tidying up the text data
textdata <- tm_map(textdata, stripWhitespace)
textdata <- tm_map(textdata, content_transformer(tolower))
textdata <- tm_map(textdata, removeWords, stopwords("english"))
textdata <- tm_map(textdata, removePunctuation)
```

Now, we are ready to generate the word cloud. The cloud is square when embedded here, but when saved to a file it appears more circular.

```{r wordcloud, fig.width=9, message=FALSE, warning=FALSE}
# Selecting the color palette from the RColorBrewer package
cols <- brewer.pal(8, "Dark2") # One of the better palettes for this

wordcloud(textdata, scale=c(6,0.2), max.words=200, random.order=F, 
          rot.per=0.1, use.r.layout=F, colors=cols)
```
